[2023-11-19T18:09:41.929+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Projet.Extract manual__2023-11-19T18:09:34.683703+00:00 [queued]>
[2023-11-19T18:09:42.008+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Projet.Extract manual__2023-11-19T18:09:34.683703+00:00 [queued]>
[2023-11-19T18:09:42.009+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2023-11-19T18:09:42.088+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): Extract> on 2023-11-19 18:09:34.683703+00:00
[2023-11-19T18:09:42.293+0000] {standard_task_runner.py:57} INFO - Started process 160 to run task
[2023-11-19T18:09:42.337+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'Projet', 'Extract', 'manual__2023-11-19T18:09:34.683703+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag_sample.py', '--cfg-path', '/tmp/tmp22ni8ij4']
[2023-11-19T18:09:42.415+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask Extract
[2023-11-19T18:09:43.720+0000] {task_command.py:416} INFO - Running <TaskInstance: Projet.Extract manual__2023-11-19T18:09:34.683703+00:00 [running]> on host 4a664210de45
[2023-11-19T18:09:47.047+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Projet' AIRFLOW_CTX_TASK_ID='Extract' AIRFLOW_CTX_EXECUTION_DATE='2023-11-19T18:09:34.683703+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-11-19T18:09:34.683703+00:00'
[2023-11-19T18:09:47.640+0000] {warnings.py:109} WARNING - /opt/***/dags/dag_sample.py:15: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
  df_urgences = pd.read_csv(csv_file_path_sos, delimiter=';', dtype={'Code tranches d\'age': str})

[2023-11-19T18:09:49.273+0000] {python.py:194} INFO - Done. Returned value was: (   Code tranches d'age             Age
0                    0       tous âges
1                    1         0-4 ans
2                    2        5-14 ans
3                    3       15-44 ans
4                    4       45-74 ans
5                    5       65-74 ans
6                    6  75 ans ou plus,         dep date_de_passage  ...  nbre_acte_tot_h  nbre_acte_tot_f
0         1      2022-12-26  ...              NaN              NaN
1         1      2022-12-26  ...              NaN              NaN
2         1      2022-12-26  ...              NaN              NaN
3         1      2022-12-26  ...              NaN              NaN
4         1      2022-12-26  ...              NaN              NaN
...     ...             ...  ...              ...              ...
214216  976      2023-10-24  ...              NaN              NaN
214217  976      2023-10-24  ...              NaN              NaN
214218  976      2023-10-24  ...              NaN              NaN
214219  976      2023-10-24  ...              NaN              NaN
214220  976      2023-10-24  ...              NaN              NaN

[214221 rows x 18 columns],     num_dep                 dep_name                 region_name
0        01                      Ain        Auvergne-Rhône-Alpes
1        02                    Aisne             Hauts-de-France
2        03                   Allier        Auvergne-Rhône-Alpes
3        04  Alpes-de-Haute-Provence  Provence-Alpes-Côte d'Azur
4        05             Hautes-Alpes  Provence-Alpes-Côte d'Azur
..      ...                      ...                         ...
96      971               Guadeloupe                  Guadeloupe
97      972               Martinique                  Martinique
98      973                   Guyane                      Guyane
99      974               La Réunion                  La Réunion
100     976                  Mayotte                     Mayotte

[101 rows x 3 columns])
[2023-11-19T18:09:50.002+0000] {xcom.py:661} ERROR - ("Could not convert '16' with type str: tried to convert to int64", 'Conversion failed for column dep with type object'). If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-11-19T18:09:50.047+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2479, in xcom_push
    XCom.set(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom.py", line 244, in set
    value = cls.serialize_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom.py", line 659, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.8/json/__init__.py", line 234, in dumps
    return cls(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/json.py", line 102, in encode
    o = self.default(o)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/json.py", line 91, in default
    return serialize(o)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/serialization/serde.py", line 145, in serialize
    return encode(classname, version, serialize(data, depth + 1))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/serialization/serde.py", line 124, in serialize
    return [serialize(d, depth + 1) for d in o]
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/serialization/serde.py", line 124, in <listcomp>
    return [serialize(d, depth + 1) for d in o]
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/serialization/serde.py", line 143, in serialize
    data, classname, version, is_serialized = _serializers[qn].serialize(o)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/serialization/serializers/pandas.py", line 49, in serialize
    table = pa.Table.from_pandas(o)
  File "pyarrow/table.pxi", line 3557, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/pandas_compat.py", line 624, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/pandas_compat.py", line 598, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/pandas_compat.py", line 592, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 316, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 100, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: ("Could not convert '16' with type str: tried to convert to int64", 'Conversion failed for column dep with type object')
[2023-11-19T18:09:50.123+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=Projet, task_id=Extract, execution_date=20231119T180934, start_date=20231119T180941, end_date=20231119T180950
[2023-11-19T18:09:50.148+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 4 for task Extract (("Could not convert '16' with type str: tried to convert to int64", 'Conversion failed for column dep with type object'); 160)
[2023-11-19T18:09:50.207+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2023-11-19T18:09:50.368+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
